{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3a9e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/alexskv/seminar_2/core', '/home/alexskv/seminar_2', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/alexskv/segm-env/lib/python3.10/site-packages']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 11:56:35.643614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-14 11:56:35.658240: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-14 11:56:35.662526: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-14 11:56:35.676029: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-14 11:56:36.372679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 4 датасетов:\n",
      "  /home/alexskv/seminar_2/data/task1\n",
      "  /home/alexskv/seminar_2/data/task4\n",
      "  /home/alexskv/seminar_2/data/task2\n",
      "  /home/alexskv/seminar_2/data/task3\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  23%|█████████████████▍                                                           | 7/31 [00:16<00:57,  2.41s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split, DataLoader, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Повторяем подготовку данных\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "seminar_path = \"/home/alexskv/seminar_2\"\n",
    "seminar_path = Path(seminar_path)\n",
    "data_path = f\"{seminar_path}/data\"\n",
    "sys.path.insert(0, f\"{seminar_path}/core\")\n",
    "print(sys.path)\n",
    "\n",
    "from dataset import SimpleCocoDataset\n",
    "from trainers import SimpleSegmentationTrainer\n",
    "\n",
    "#Определяем параметры даталодера \n",
    "resize = (512, 512)\n",
    "batch_size = 32\n",
    "\n",
    "pathology_ids = [i for i in range(6, 27) if i != 15]\n",
    "\n",
    "\n",
    "#Создаем классы, так же берем только патологию.\n",
    "out_classes = [{\"id\": 1, \"name\": \"Патология\", \"summable_masks\": pathology_ids,    \"subtractive_masks\": []}]\n",
    "\n",
    "base_names = [\n",
    "    \"Правое лёгкое\", \"Левое лёгкое\", \"Контуры сердца\", \"Купола диафрагмы и нижележащая область\",\n",
    "    \"Сложный случай\", \"нельзя составить заключение\", \"Иная патология\", \"Гидроторакс\",\n",
    "    \"Легочно-венозная гипертензия 2 стадии и выше\", \"Пневмоторакс\", \"Доброкачественное новообразование\",\n",
    "    \"Перелом ребра свежий\", \"Буллезное вздутие, тонкостенная киста\", \"Рак лёгкого (включая дорожку к корню при наличии)\",\n",
    "    \"Кардиомегалия (отмечается всё сердце, как патология)\", \"Интерстициальная пневмония.\",\n",
    "    \"Метастатическое поражение лёгких\", \"Полость с уровнем жидкости\", \"Грыжа пищевого отверстия диафрагмы\",\n",
    "    \"Спавшийся сегмент лёгкого при ателектазе\", \"Инфильтративный туберкулёз\",\n",
    "    \"Пневмония. В том числе сегментарная и полисегментарная\", \"Область распада, деструкции тканей лёгкого\",\n",
    "    \"Участок пневмофиброза\", \"Кальцинаты. Каждый кальцинат выделяется отдельным контуром\",\n",
    "    \"Консолидированный перелом ребра\"\n",
    "]\n",
    "\n",
    "base_classes = [{\"id\": i+1, \"name\": name} for i, name in enumerate(base_names)]\n",
    "\n",
    "\n",
    "data_roots = {p.parent.parent for p in (seminar_path / \"data\").rglob(\"annotations/instances_default.json\")}\n",
    "print(f\"Найдено {len(data_roots)} датасетов:\", *data_roots, sep=\"\\n  \")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Сбор и разделение данных\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "datasets = [SimpleCocoDataset(str(d), base_classes, out_classes, resize=resize)\n",
    "            for d in sorted(data_roots)]\n",
    "\n",
    "full_ds = ConcatDataset(datasets)\n",
    "val_percent = 0.2\n",
    "val_size = int(len(full_ds) * val_percent)\n",
    "train_size = len(full_ds) - val_size\n",
    "train_ds, val_ds = random_split(full_ds, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "val_loader = DataLoader(val_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=4)\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Модель сегментации на базе Unet + EfficientNet-b0 encoder\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b0\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=1,\n",
    "    classes=1  # фон, норма, патология\n",
    ")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4. Запуск обучения сегментации\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainer = SimpleSegmentationTrainer(\n",
    "    model=model,\n",
    "    classes = out_classes,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    epochs=10,\n",
    "    exp_name=\"efficientnet_segmentation\"\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662adae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ff430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad842e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
